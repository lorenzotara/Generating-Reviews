{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an LSTM in order to generate reviews automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LINK TO THE DATA\n",
    "* In the section below you will find the entire process of generating random reviews of beers, starting from a dataset of 2.924.163 reviews.\n",
    "* Since I am using the CPU of my computer (MacBook Pro 2,5 GHz Intel Core i7), I have faced some difficulties for what regards time complexity. I will explain why later in details, but I had to choose 100.000 reviews for the moment as starting training dataset to feed in the LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* All the prerequisites you need are explained in the linked [github page](https://github.com/jcjohnson/torch-rnn). If you are using OSX, you can find a tutorial written by Jeff Thompson [here](http://www.jeffreythompson.org/blog/2016/03/25/torch-rnn-mac-install/).\n",
    "* You should clone the [repository](https://github.com/jcjohnson/torch-rnn) inside this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "* First of all, from this [beer dataset](http://jmcauley.ucsd.edu/cse255/data/beer/) I used the file Ratebeer.txt.gz, that contains almost 3 million reviews of beers.\n",
    "* One sample of review is shown below:<br>\n",
    "`beer/name: John Harvards Simcoe IPA\n",
    "beer/beerId: 63836\n",
    "beer/brewerId: 8481\n",
    "beer/ABV: 5.4\n",
    "beer/style: India Pale Ale &#40;IPA&#41;\n",
    "review/appearance: 4/5\n",
    "review/aroma: 6/10\n",
    "review/palate: 3/5\n",
    "review/taste: 6/10\n",
    "review/overall: 13/20\n",
    "review/time: 1157587200\n",
    "review/profileName: hopdog\n",
    "review/text: On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.`\n",
    "* Since we are interested in only the actual reviews text, and not the various scores, the code below has the function to extract only the contents we are interested in and save them in a file.\n",
    "* You can change the number of reviews to save and the file name where they will be saved changing the two variables `max_reviews` and `file_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total reviews = 2.924.163\n",
    "\n",
    "file_length = 0\n",
    "max_reviews = 100000\n",
    "file_name = 'reviews_small.txt'\n",
    "reviews = []\n",
    "with open('ratebeer.txt', 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        try:\n",
    "            line = line.decode(\"utf-8\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            del_index = line.index(':')\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        if line[:del_index] == 'review/text':\n",
    "            file_length += 1\n",
    "            with open(file_name, 'a') as new_file:\n",
    "                new_file.write(line[del_index+2:])\n",
    "            \n",
    "        if file_length >= max_reviews:\n",
    "            break\n",
    "            \n",
    "file_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After this step, you have \n",
    "* I will be using the [LSTM network](https://github.com/jcjohnson/torch-rnn) implemented by [Justin Johnson](http://cs.stanford.edu/people/jcjohns/). He hardcodes an RNN/LSTM with torch in a very efficient way. You can find every statistics about the model on the github page linked above.\n",
    "* As explained by Justin, in order to work with his network, we have to preprocess the data using his function of preprocessing (`preprocess.py`). This function will create an HDF5 file and JSON file containing a preprocessed version of the data. Moreover it will split the data in training, validation and test, default sizes: 0.1. I decided to use the default sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 100\n",
      "Total tokens in file: 30653625\n",
      "  Training size: 24522901\n",
      "  Val size: 3065362\n",
      "  Test size: 3065362\n",
      "Using dtype  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "%run -i \"torch-rnn-master/scripts/preprocess.py\" --input_txt reviews_small.txt --output_h5 reviews_small.h5 --output_json reviews_small.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training\n",
    "\n",
    "* Following the procedure described by Justin Johnson, I trained an LSTM network in different ways.\n",
    "* NOTE: I found an error in the `hfd5` library. The error I was receiving after launching the train command was: `/torch/install/share/lua/5.1/hdf5/ffi.lua:56: ')' expected near '_close' at line 1436`.<br>\n",
    "<br>\n",
    "If you have the same problem you can try to follow the following procedure:<br>\n",
    "`Edit ffi.lua - hdf5 - line 44,\n",
    "change\n",
    "local process = io.popen(\"gcc -E \" .. headerPath) -- TODO pass -I\n",
    "to\n",
    "local process = io.popen(\"gcc -D '_Nullable=' -E \" .. headerPath) -- TODO pass -I.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.000 samples\n",
    "\n",
    "* First I trained the LSTM network with 10.000 reviews for only 10 epochs. In order to do so type the following commands in the shell:<br>\n",
    "`cd torch-rnn-master`<br>\n",
    "`th train.lua -input_h5 reviews_very_small.h5 -input_json reviews_very_small.json -max_epochs 10 -gpu -1`<br><br>\n",
    "\n",
    "* `-gpu -1` means that I am going to use the cpu instead of the gpu. As default, `-model_type` is LSTM, `-wordvec_size` is 64, `-rnn_size` (number of hidden units in the RNN/LSTM) is 128, `-num_layers` is 2, `-learning_rate` is 2e-3.<br><br>\n",
    "\n",
    "* The final validation loss was: 1.2175781618465.<br><br>\n",
    "\n",
    "* Now that the model is trained we can try to make a sample review:<br>\n",
    "`th sample.lua -checkpoint cv/reviews_very_small/checkpoint_9710.t7 -gpu -1 -length 500`<br><br>\n",
    "\n",
    "* This is the sample output:<br>\n",
    "`Ahats black copper, esperis - mid-dark aromas wet lingering the glass. Malty and lest, rettheas.\tThe body is medium fruity is black pepper. Aroma of sweet aremilen rough peal yeast tite warm fair beins. Dry like all a strong gives has many tongue.  I love the (pan yet is skors an clear spicy brown with an away bittering but leaves over that can beautiful lonced for. Nose of taste except.\n",
    "330ml bottle bottle. An aroma of hops you cann: Ive definet about on the Chimay a tongue.\n",
    "Ontent at reddish a` (1)<br><br>\n",
    "* We can observe that the LSTM has learnt how to separate words and how to use punctuation. It opens one bracket and never close it. Some words do not exist and any sentence as a clear sense. As default, the `-temperature` argument is set to 1: this means that the LSTM will produce a noiser sample, trying to use \"difficult\" words.<br><br>\n",
    "* Trying to reduce the `-temperature` to 0.7 we can see the following output:<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_very_small/checkpoint_9710.t7 -gpu -1 -length 500 -temperature 0.7`<br><br>\n",
    "`:2A, 2007 As a detected was off-white head.  Reddish brown color, but not solid carbonation in the flavor.\n",
    "Chewish as the pale in the head time Monks this one.\n",
    "Bottle @ Wallen 07/10,0755. 9 start beer diminished something to have a Brunks like this one beers as well.  Pours a bit finish, wanth an average off white head that being the mouth and alcohol.\n",
    "UPDATED: MAY 18, 2008 Taste is a nice creamy that rich toasty nose and bready flavors, finish is smooth.  Its some clove and a nice bitter slight` (2)<br><br>\n",
    "* The sentences have a slightly more sense, there are no wrong words, even if the review starts with: `:2A,`. It seems that it is understanding how to use subject + verb + rest of the sentence, but most of the sentences don't have a verb.<br><br>\n",
    "* Before trying to use a bigger dataset (which training is going to take a lot of time, ~40 hours), I would like to see how much the output changes if I use a \"better\" model: `-num_layers 3`, `-rnn_size 256`, `-max_epochs 30`.<br><br>\n",
    "`th train.lua -input_h5 reviews_very_small.h5 -input_json reviews_very_small.json -num_layers 3 -rnn_size 256 -gpu -1 -max_epochs 30`.<br><br>\n",
    "* The validation loss is: 1.106896893052<br><br>\n",
    "* That's how you get the new sample:<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_very_small_better/checkpoint_29130.t7 -gpu -1 -length 500`<br><br>\n",
    "* Output for temperature = 1:<br><br>\n",
    "`st..\ta little boring... this suse apple flavors, slight alcohol - the hops togething of fruity, simble herb.  Flavor remains fresh, its somewhat flavors.  Id immediately enjoy.\n",
    "Cloudy reddish amber with lots of frothing tan head. Yeast with a floral palate (deep amber brown. Fraisy and smooy malt and fruit.  Spice and caramel level.\n",
    "Nothing too sweet dark and fruity than papais and though the whole point, this food\n",
    "Draft at brewpub?  Full, beige cocoa, with hurty off-white head retrocal lacing` (3)<br><br>\n",
    "Not exactly what I was hoping, but still slightly better. Sentences seem to have more sense, but still we can observe that the model prefer not to use verbs, it does not know how to open/close brackets.<br><br>\n",
    "* Output for temperature = 0.7:<br><br>\n",
    "`ad 2006.  The aroma on the tongue leaving a strong mouth feel that lingers on the palate. Very steaky straw, but a bit lively carbonation.\t\tThe flavor starts sweet w/ some malt and spices, bitter and spicy. Its well carbonated than I expected.  A bit cloudy and cloudy brown with a big head is off white colored bubbles. Moderately sweet with some hay, grassy hops and banana sugar.  Taste of chocolate, and chocolate. Medium bodied and slightly bitter finish.  Medium bodied with a sharp hop bitter\t` (4)<br><br>\n",
    "Using a lower temperature we can note repetitions in the review, but it has way more sense than before. Except for one sentence that clearly does not make any sense (`A bit cloudy and cloudy brown with a big head is off white colored bubbles`), we can detect an improvement from the output (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100.000 samples\n",
    "\n",
    "* Now I'll repeat the same process for 100.000 reviews. Using the default arguments (30 epochs) it took around ~15 hours to train the model. Using `-num_layers 3` `-rnn_size 256`, `-gpu -1`, `-max_epochs 20` it took ~40 hours.<br><br>\n",
    "* So, first I run:\n",
    "`th train.lua -input_h5 reviews_small.h5 -input_json reviews_small.json -gpu -1 -max_epochs 30`<br><br>\n",
    "The validation loss is 1.036688855382.<br>\n",
    "The sample output for `-temperature 1` is:<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_small_30epochs/checkpoint_294270.t7 -gpu -1 -length 500`<br><br>\n",
    "`K@8{_yl, Hazy golden color with a good beer.  White head. Dusty and spicy head with small head.  The aroma is like a sweetish with a little to fine persistent hop comy of alcohol, and is predominate a drinking me.  Strong hints of - the oily after a touch apricot.  The flavor is sweet, dry finish. Some rich, bitter coffee, grain aroma. Good malt.  average sweet bite. Good sign-spicy alcohol and peaches. Its very balanced product outly in the same, as it quickler beer. This Russian. And it is, a`(5)<br><br>\n",
    "We can clearly see more complex sentences, even if it's not still very correct. The beginning of the review is no sense (`K@8{_yl,`). Let's the differences with `-temperature 0.7`.<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_small_30epochs/checkpoint_294270.t7 -gpu -1 -length 500 -temperature 0.7`<br><br>\n",
    "`/11. A sweet chocolate sweet aroma with some earthy hops.\n",
    "Bottle at the Beer Festival at the Grand iPcome on Total tasting & London. Sweet aroma of malt and yeast and some strong spices and caramel.  Taste is slightly lighter sweet and clean aftertaste.  Some light spices, but not soft finish. Not complex malts and some bitterness on the back a lot of drinkability. I like the style.  Malt malt sweetness.  Decent brew\n",
    "Light amber color with a thick large beige head. Sweet malt aroma with a dry h`(6)<br><br>\n",
    "This is the first review that overall makes sense. Some words do not exist, like `iPcome`. Others are repeated several times: `sweet`, `malt` and `spices` for example. But we can say that with 10 times more data the LSTM is working way better. We can denote that the validation loss is very similar to the one obtained using 10.000 samples, but with more hidden units and layers. So we should find a better result if we try to use the \"better\" model on the 100.000 reviews.<br><br>\n",
    "\n",
    "* Last run (for the moment) - I used 20 epochs instead of 30 because it was going to take 60 hours on my computer:<br>\n",
    "`th train.lua -input_h5 reviews_small.h5 -input_json reviews_small.json -num_layers 3 -rnn_size 256 -gpu -1 -max_epochs 20 -checkpoint_every 10000`<br><br>\n",
    "The validation loss is 0.91980762436962 (improvement from the 1.037 of before).<br>\n",
    "Let's see the output for temperature 1:<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_small_better/checkpoint_196180.t7 -gpu -1 -length 500`<br><br>\n",
    "`NB). Great ale. #8-X11/09+ version of a pilsener, but it is definitely a very nice ale. No aroma, slightly sweet and nutty with some coffee. Theres no looking finish that fades to mind and chewy earthy on the pils finish. Palate really work down which offered after Dug, the Had up, but whiskey nicely schools. Muenentableons.\n",
    "On tap at DBST but thats awesome.\t\tPours a clear dark brown with light head. Hoppy aroma with fter bitterness and a tad of a taste, with a honey backbone. Bitter finish, yea`<br><br>\n",
    "As always, setting the temperature at 1 doesn't give good results, even if we can observe that the number of words used and the variety of them is higher than before. Let's see with `-temperature 0.7` what is the output:<br><br>\n",
    "`th sample.lua -checkpoint cv/reviews_small_better/checkpoint_196180.t7 -gpu -1 -length 500 -temperature 0.7`<br><br>\n",
    "`3o bottle the colour is a cloudy golden body with a small white head.  Sweet fruity aroma, light body, a fine toasted and grainy flavor with a little bit of fruit that I thought it was so well still as bitterness.  Wow.  I have been pudded with a stouts but I have had to get a nice complex beer to me.\n",
    "Bottle. Pours a clear golden yellow with a thick tan head. Aroma is light malty with hints of banana, and some hops, malty and caramel. Medium bodied with very soft carbonation. Flavour is moderate`<br><br>\n",
    "Here is another example:<br><br>\n",
    "`< Small body.  Aroma is sweet malt and toffee, with a bit of soft citrus hops and some bourbon.  Very smooth on the palate and too much carbonation.  It is very tasty, but I was expecting a mix of sweet malt in the finish.  I can quite expect from a good beer and easily a great beer.\n",
    "Bottle: Pours a pale gold color with a large bubbly beige head. Nose of spices, peaches, coffee, and some caramel. Flavor is very dry with metal texture, with a bit of spicy hops. Medium body with soft carbonation.`<br><br>\n",
    "Ok, these are maybe not perfect reviews, but we are going closer and closer to our goal. The model started to use more complex sentences, using present perfect, longer sentences with more sense than before.<br><br>\n",
    "\n",
    "* For completeness I am going to show you the results with the temperature set to lower values. <br><br>\n",
    "    1) temperature 0.5: <p>`Ws courtesy of Dickinson and beers and had more abv in the face to find.  Its still not as good as the white expected the style, but I would be a great beer for a pale ale, but I would have liked to be as good as I would drink.\n",
    "Bottle.  Clear amber color with a small white head.  The aroma is sweet with hints of caramel and pine.  Taste is sweet and smooth with a nice hop finish.  Very good beer.\n",
    "Bottle from Seeble Market Room bottle from Billian Strong Ale Festival of Ales, Street and Local Ale`<p>\n",
    "    2) temperature 0.1: <p>`Y bottle from the brewery.  Pours a clear amber with a small white head.  Aroma is sweet malts, caramel, and a touch of caramel.  Flavor is sweet and sweet with a light bitterness.  A bit of a bitter finish.  The finish is sweet and slightly bitter.  The finish is sweet and slightly sweet.  The finish is sweet and slightly bitter.  The finish is slightly bitter and slightly bitter.  The finish is sweet and slightly bitter.  Not bad.\n",
    "Bottle.  Pours a clear amber with a small white head.  Aroma is\t`<p>\n",
    "\n",
    "* We can see that the smaller the temperature gets, the more repetetive the sentences become. These repetitions are due to the fact that if the temperature is lower, the output is less noisy, meaning that the model will use only terms and sentence's constructs of which it is more \"sure\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Train at least 1 million reviews on the LSTM using a gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
